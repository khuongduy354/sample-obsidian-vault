---
id: "2023-11-02"
aliases:
  - "November 2, 2023"
tags:
  - "daily-notes"
---

# November 2, 2023

Todos for cdf:

- [ ] Set up configuration to pull destinations from both dlt config accessors AND env vars, unify the notation
- [ ] Add support to bulk delete/toggle feature flags
- [ ] Add sqlmesh command passthrough
- [ ] Add sqlmesh loader subclass which pulls external models from dlt
- [ ] Consider how we can cache the dlt models in a way that is cheaper to grab than in the data store

Considerations on dlt -> sqlmesh external models:

Dynamic is bad
Batched changes are good
Automated is good
Automated batch changes are good

I am iterating
suddenly plan asks for breaking/non breaking of external model column?

Data contract between downstream data models and external tables/sources should be sound and unchanging
unless part of a PR + plan + apply cycle.

Money shot?
1. We need a command which pulls dlt metadata into a centralized location
2. We may ammend the command sqlmesh uses to pull metadata such that both dlt and sqlmesh output to the same dir
  a) we may want to break up the sqlmesh yaml by schema so that the directory has nice layout
3. They may or may not be YAML, whatever is preferable
4. We can wrap all metadata generation in a single unifying CLI command
5. We can override the external models loader method to consume from the `metadata/<schema>/schema.yml` using a format that combines both dlt + sqlmesh metadata
6. We can override python model loader to consume from `metadata/<schema>/staging.yml` which uses rulesets to generate entire staging datasets for all raw tables
  a) Due to the commonalities between transformations, python functions that operate on SQLGlot ASTs will drive enacting the rules in conjunction with the metadata. The build up of these over time is extremely valuable
  b) Rules will be expressed as I think of things we want to do, and will be driven by the metadata
  c) We should have a breakglass that lets us define arbitrary strings parsed by sqlglot and added to the projection/predicate
  d) Audits, grain, etc should be automated at this layer

NOTES:

Need to study dlt metadata format and be extremely sound in understanding
SQLMesh metadata should be able to live in the exact same data structure, we can override method in loader to be happy with this
This reduces 2 files per schema with lots of repetitive info to 1 file
We may want to colocate some yaml type of file containing rulesets that allow us to automatically generate the staging layer for every single schema YES lets goooo


dlt allows arbitrary metadata by prefixing with `x-`


Layout

```
❯ tree . --dirsfirst
.
├── audits
│   └── assert_positive_order_ids.sql
├── macros
│   └── __init__.py
├── metadata
│   ├── asana_v1
│   │   └── schema.yml
│   └── salesforce_v1
│       └── schema.yml
├── models
│   ├── full_model.sql
│   ├── incremental_model.sql
│   └── seed_model.sql
├── seeds
│   └── seed_data.csv
├── sources
│   ├── __init__.py
│   ├── asana.py
│   └── salesforce.py
├── tests
│   └── test_full_model.yaml
├── cdf_config.toml
├── cdf_secrets.toml
└── config.yaml

10 directories, 15 files
```
